Steps,Policy/Entropy,Environment/Episode Length,High Score,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Policy/Extrinsic Reward,Losses/Value Loss,Losses/Policy Loss,Policy/Learning Rate,Is Training
10000,0.64506626,15.024,14.0,-0.0379192,-0.8524038396202601,-0.8524038396202601,0.32653606,0.0729144,0.0002999691,1.0
20000,0.4514,29.927672955974842,None,-0.64030874,-0.8394984242544279,-0.8394984242544279,0.049134683,0.06284125,0.00029991328,1.0
30000,0.25861886,53.927374301675975,None,-0.6253736,-0.8539325761493672,-0.8539325761493672,0.027041536,0.071561776,0.00029985132,1.0
40000,0.15288596,100.7127659574468,None,-0.5340491,-0.7734042434616292,-0.7734042434616292,0.023313137,0.07161076,0.00029978936,1.0
50000,0.10414941,138.37313432835822,None,-0.4265233,-0.7588235204491545,-0.7588235204491545,0.021397134,0.067566,0.00029972647,1.0
60000,0.09382454,144.04,None,-0.3881355,-0.7810810701669874,-0.7810810701669874,0.021109276,0.07169124,0.00029967012,1.0
70000,0.08666782,190.17073170731706,None,-0.34574452,-0.754761897382282,-0.754761897382282,0.01854531,0.07494153,0.00029961325,1.0
80000,0.09001471,276.125,18.0,-0.24286689,-0.49999998341644963,-0.49999998341644963,0.016000733,0.06452009,0.0002995497,1.0
90000,0.07532004,471.6363636363636,27.0,-0.16170886,-0.08260867388352104,-0.08260867388352104,0.01274015,0.06405635,0.0002994863,1.0
100000,0.07059115,446.25,32.0,-0.09708623,-0.12499998472630977,-0.12499998472630977,0.018836783,0.06889272,0.00029942958,1.0
110000,0.06287443,560.2,None,-0.033166897,0.3600000282128652,0.3600000282128652,0.012951595,0.068432994,0.00029937344,1.0
120000,0.06797709,502.3333333333333,33.0,0.0007627742,1.951342537289574e-08,1.951342537289574e-08,0.018052686,0.067542784,0.00029931002,1.0
130000,0.07288664,464.2857142857143,50.0,0.024109347,-0.10714283532329968,-0.10714283532329968,0.012175376,0.06548934,0.0002992474,1.0
