Steps,Policy/Entropy,High Score,Environment/Episode Length,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Policy/Extrinsic Reward,Losses/Value Loss,Losses/Policy Loss,Policy/Learning Rate,Is Training
10000,0.64910203,9.0,16.39160839160839,-0.19477037,-0.8355516559997289,-0.8355516559997289,0.1930877,0.074074686,0.00029996893,1.0
20000,0.4205605,13.0,43.84090909090909,-0.6135955,-0.7927601723109975,-0.7927601723109975,0.040478513,0.06491379,0.00029991224,1.0
30000,0.23344581,14.0,102.75280898876404,-0.46140242,-0.7213483045945007,-0.7213483045945007,0.026676621,0.066076174,0.00029984902,1.0
40000,0.12046894,22.0,202.82051282051282,-0.3022567,-0.5999999892635223,-0.5999999892635223,0.0193343,0.066698894,0.00029978584,1.0
50000,0.069928266,39.0,293.04761904761904,-0.15830754,-0.39999998964014505,-0.39999998964014505,0.01792917,0.059429497,0.0002997287,1.0
60000,0.055562504,57.0,621.6666666666666,-0.044110503,0.4916666882733504,0.4916666882733504,0.010629425,0.07193209,0.00029967213,1.0
70000,0.049632672,63.0,617.5454545454545,0.025458857,0.5000000284476713,0.5000000284476713,0.013538097,0.06579224,0.0002996101,1.0
80000,0.046224523,None,1159.6,0.08595505,1.9000000648200512,1.9000000648200512,0.011759782,0.06539735,0.00029954722,1.0
